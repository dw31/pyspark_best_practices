{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Embracing Pure Functions and Minimizing Side Effects\n",
    "\n",
    "This notebook demonstrates how to apply functional programming principles in PySpark by creating pure functions and minimizing side effects.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand what makes a function \"pure\" in the context of PySpark\n",
    "- Learn to separate transformation logic from side effects\n",
    "- Practice creating testable, reusable transformation functions\n",
    "- Understand when and how to use actions wisely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Pure Function?\n",
    "\n",
    "A **pure function** is a function that:\n",
    "1. **Given the same input, always produces the same output** (deterministic)\n",
    "2. **Has no observable side effects** (doesn't modify external state, perform I/O, etc.)\n",
    "\n",
    "In PySpark context:\n",
    "- Pure functions take DataFrames as input and return DataFrames as output\n",
    "- They don't call actions like `show()`, `collect()`, or `write()`\n",
    "- They don't modify global variables or external state\n",
    "- They leverage Spark's immutability to ensure predictable behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# Sample sales data for demonstration\n",
    "sales_data = [\n",
    "    (\"2023-01-15\", \"Alice\", \"Laptop\", 1200.00, \"Electronics\"),\n",
    "    (\"2023-01-16\", \"Bob\", \"Coffee Maker\", 89.99, \"Appliances\"),\n",
    "    (\"2023-01-17\", \"Charlie\", \"Book\", 15.99, \"Books\"),\n",
    "    (\"2023-01-18\", \"Diana\", \"Headphones\", 199.99, \"Electronics\"),\n",
    "    (\"2023-01-19\", \"Eve\", \"Desk Chair\", 299.99, \"Furniture\"),\n",
    "    (\"2023-01-20\", \"Frank\", \"Smartphone\", 699.99, \"Electronics\"),\n",
    "    (\"2023-01-21\", \"Grace\", \"Blender\", 79.99, \"Appliances\")\n",
    "]\n",
    "\n",
    "sales_schema = StructType([\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"customer\", StringType(), True),\n",
    "    StructField(\"product\", StringType(), True),\n",
    "    StructField(\"amount\", DoubleType(), True),\n",
    "    StructField(\"category\", StringType(), True)\n",
    "])\n",
    "\n",
    "sales_df = spark.createDataFrame(sales_data, sales_schema)\n",
    "print(\"Sample Sales Data:\")\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Pure Functions vs Impure Functions\n",
    "\n",
    "Let's examine the difference between pure and impure functions in PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ PURE FUNCTION EXAMPLE\n",
    "def add_tax_column_pure(df, tax_rate=0.08):\n",
    "    \"\"\"\n",
    "    Pure function: adds tax calculation to DataFrame\n",
    "    - Takes DataFrame as input, returns DataFrame as output\n",
    "    - No side effects (no I/O, no external state modification)\n",
    "    - Deterministic: same input always produces same output\n",
    "    \"\"\"\n",
    "    return df.withColumn(\"tax\", F.col(\"amount\") * F.lit(tax_rate)) \\\n",
    "             .withColumn(\"total_with_tax\", F.col(\"amount\") + F.col(\"tax\"))\n",
    "\n",
    "# ❌ IMPURE FUNCTION EXAMPLE\n",
    "def add_tax_column_impure(df, tax_rate=0.08):\n",
    "    \"\"\"\n",
    "    Impure function: has side effects\n",
    "    - Calls show() which is an action (side effect)\n",
    "    - Prints to console (side effect)\n",
    "    - Makes the function harder to test and reuse\n",
    "    \"\"\"\n",
    "    result_df = df.withColumn(\"tax\", F.col(\"amount\") * F.lit(tax_rate)) \\\n",
    "                  .withColumn(\"total_with_tax\", F.col(\"amount\") + F.col(\"tax\"))\n",
    "    \n",
    "    # Side effects - these make the function impure!\n",
    "    print(f\"Applied tax rate: {tax_rate}\")\n",
    "    result_df.show()  # Action with side effect\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "print(\"=== Demonstrating Pure vs Impure Functions ===\")\n",
    "print(\"\\n1. Pure function - no side effects:\")\n",
    "pure_result = add_tax_column_pure(sales_df)\n",
    "print(\"Pure function executed - no output yet because no action called\")\n",
    "\n",
    "print(\"\\n2. Impure function - has side effects:\")\n",
    "impure_result = add_tax_column_impure(sales_df)\n",
    "print(\"Impure function executed - notice the side effects above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Library of Pure Transformation Functions\n",
    "\n",
    "Let's create a collection of pure functions that can be composed together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Collection of Pure Transformation Functions\n",
    "\n",
    "def standardize_dates(df, date_column=\"date\"):\n",
    "    \"\"\"\n",
    "    Pure function: converts string dates to proper date format\n",
    "    \"\"\"\n",
    "    return df.withColumn(date_column, F.to_date(F.col(date_column), \"yyyy-MM-dd\"))\n",
    "\n",
    "def categorize_purchase_size(df, amount_column=\"amount\"):\n",
    "    \"\"\"\n",
    "    Pure function: categorizes purchases by amount\n",
    "    \"\"\"\n",
    "    return df.withColumn(\"purchase_size\",\n",
    "                        F.when(F.col(amount_column) < 50, \"Small\")\n",
    "                         .when(F.col(amount_column) < 200, \"Medium\")\n",
    "                         .when(F.col(amount_column) < 500, \"Large\")\n",
    "                         .otherwise(\"Extra Large\"))\n",
    "\n",
    "def add_seasonal_info(df, date_column=\"date\"):\n",
    "    \"\"\"\n",
    "    Pure function: adds seasonal information based on date\n",
    "    \"\"\"\n",
    "    return df.withColumn(\"month\", F.month(F.col(date_column))) \\\n",
    "             .withColumn(\"season\",\n",
    "                        F.when(F.col(\"month\").isin([12, 1, 2]), \"Winter\")\n",
    "                         .when(F.col(\"month\").isin([3, 4, 5]), \"Spring\")\n",
    "                         .when(F.col(\"month\").isin([6, 7, 8]), \"Summer\")\n",
    "                         .otherwise(\"Fall\"))\n",
    "\n",
    "def filter_high_value_customers(df, threshold=100.0):\n",
    "    \"\"\"\n",
    "    Pure function: filters for customers with purchases above threshold\n",
    "    \"\"\"\n",
    "    return df.filter(F.col(\"amount\") >= threshold)\n",
    "\n",
    "def calculate_customer_metrics(df):\n",
    "    \"\"\"\n",
    "    Pure function: calculates aggregated metrics per customer\n",
    "    \"\"\"\n",
    "    return df.groupBy(\"customer\") \\\n",
    "             .agg(F.sum(\"amount\").alias(\"total_spent\"),\n",
    "                  F.avg(\"amount\").alias(\"avg_purchase\"),\n",
    "                  F.count(\"*\").alias(\"purchase_count\"),\n",
    "                  F.max(\"amount\").alias(\"max_purchase\"))\n",
    "\n",
    "print(\"Pure transformation functions defined!\")\n",
    "print(\"These functions can be composed together without side effects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing Pure Functions\n",
    "\n",
    "Now let's demonstrate how pure functions can be easily composed and chained together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Composing Pure Functions ===\")\n",
    "\n",
    "# Method 1: Using transform() method for clean composition\n",
    "print(\"\\n1. Using .transform() method:\")\n",
    "composed_pipeline = (sales_df\n",
    "                    .transform(standardize_dates)\n",
    "                    .transform(add_tax_column_pure)\n",
    "                    .transform(categorize_purchase_size)\n",
    "                    .transform(add_seasonal_info)\n",
    "                    .transform(filter_high_value_customers, 100.0))\n",
    "\n",
    "print(\"Pipeline built with .transform() - no execution yet!\")\n",
    "\n",
    "# Method 2: Direct function composition\n",
    "print(\"\\n2. Direct function composition:\")\n",
    "step1 = standardize_dates(sales_df)\n",
    "step2 = add_tax_column_pure(step1)\n",
    "step3 = categorize_purchase_size(step2)\n",
    "step4 = add_seasonal_info(step3)\n",
    "final_result = filter_high_value_customers(step4, 100.0)\n",
    "\n",
    "print(\"Pipeline built with function composition - no execution yet!\")\n",
    "\n",
    "# Method 3: Nested function calls (less readable but functional)\n",
    "print(\"\\n3. Nested composition (less readable):\")\n",
    "nested_result = filter_high_value_customers(\n",
    "    add_seasonal_info(\n",
    "        categorize_purchase_size(\n",
    "            add_tax_column_pure(\n",
    "                standardize_dates(sales_df)\n",
    "            )\n",
    "        )\n",
    "    ), 100.0\n",
    ")\n",
    "\n",
    "print(\"Pipeline built with nested calls - no execution yet!\")\n",
    "print(\"\\nAll three methods produce equivalent results due to functional purity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Transformation Logic from Actions\n",
    "\n",
    "Let's demonstrate the principle of confining side effects to the boundaries of our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Separating Pure Logic from Side Effects ===\")\n",
    "\n",
    "# ✅ GOOD PATTERN: Pure transformation pipeline + controlled actions\n",
    "def build_sales_analysis_pipeline(df):\n",
    "    \"\"\"\n",
    "    Pure function: builds the entire transformation pipeline\n",
    "    Returns the transformed DataFrame without executing actions\n",
    "    \"\"\"\n",
    "    return (df\n",
    "            .transform(standardize_dates)\n",
    "            .transform(add_tax_column_pure)\n",
    "            .transform(categorize_purchase_size)\n",
    "            .transform(add_seasonal_info)\n",
    "            .select(\"date\", \"customer\", \"product\", \"category\", \n",
    "                   \"amount\", \"total_with_tax\", \"purchase_size\", \"season\"))\n",
    "\n",
    "def execute_pipeline_with_actions(df):\n",
    "    \"\"\"\n",
    "    Function that handles all side effects:\n",
    "    - Applies transformations using pure functions\n",
    "    - Executes actions for output/persistence\n",
    "    - Confines side effects to this boundary function\n",
    "    \"\"\"\n",
    "    # Pure transformation pipeline\n",
    "    processed_df = build_sales_analysis_pipeline(df)\n",
    "    \n",
    "    # Side effects confined to this function\n",
    "    print(\"=== Sales Analysis Results ===\")\n",
    "    processed_df.show()\n",
    "    \n",
    "    print(f\"\\nTotal records processed: {processed_df.count()}\")\n",
    "    \n",
    "    # Could add more actions here:\n",
    "    # processed_df.write.mode('overwrite').parquet('/path/to/output')\n",
    "    # processed_df.createOrReplaceTempView('sales_analysis')\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Execute the pipeline\n",
    "result = execute_pipeline_with_actions(sales_df)\n",
    "\n",
    "print(\"\\nBenefits of this pattern:\")\n",
    "print(\"- Pure transformation logic is easily testable\")\n",
    "print(\"- Side effects are explicit and controlled\")\n",
    "print(\"- Pipeline can be reused with different actions\")\n",
    "print(\"- Transformations can be composed in different ways\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Pure Functions\n",
    "\n",
    "Pure functions are much easier to test because they have no side effects and are deterministic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing Pure Functions ===\")\n",
    "\n",
    "# Create test data\n",
    "test_data = [\n",
    "    (\"2023-06-15\", \"TestCustomer\", \"TestProduct\", 150.0, \"TestCategory\")\n",
    "]\n",
    "\n",
    "test_df = spark.createDataFrame(test_data, sales_schema)\n",
    "\n",
    "def test_categorize_purchase_size():\n",
    "    \"\"\"\n",
    "    Test function for purchase size categorization\n",
    "    Pure functions are easy to test!\n",
    "    \"\"\"\n",
    "    # Test with known input\n",
    "    result = categorize_purchase_size(test_df)\n",
    "    \n",
    "    # Collect result for assertion (this is OK in tests)\n",
    "    collected = result.select(\"purchase_size\").collect()\n",
    "    actual_category = collected[0][\"purchase_size\"]\n",
    "    \n",
    "    expected_category = \"Medium\"  # 150.0 should be \"Medium\"\n",
    "    \n",
    "    assert actual_category == expected_category, f\"Expected {expected_category}, got {actual_category}\"\n",
    "    print(f\"✅ Test passed: Purchase amount 150.0 correctly categorized as '{actual_category}'\")\n",
    "\n",
    "def test_add_tax_column():\n",
    "    \"\"\"\n",
    "    Test function for tax calculation\n",
    "    \"\"\"\n",
    "    # Test with known tax rate\n",
    "    result = add_tax_column_pure(test_df, 0.10)  # 10% tax\n",
    "    \n",
    "    collected = result.select(\"amount\", \"tax\", \"total_with_tax\").collect()\n",
    "    row = collected[0]\n",
    "    \n",
    "    expected_tax = 15.0  # 10% of 150.0\n",
    "    expected_total = 165.0  # 150.0 + 15.0\n",
    "    \n",
    "    assert row[\"tax\"] == expected_tax, f\"Expected tax {expected_tax}, got {row['tax']}\"\n",
    "    assert row[\"total_with_tax\"] == expected_total, f\"Expected total {expected_total}, got {row['total_with_tax']}\"\n",
    "    \n",
    "    print(f\"✅ Test passed: Tax calculation correct - Tax: {row['tax']}, Total: {row['total_with_tax']}\")\n",
    "\n",
    "def test_pipeline_composition():\n",
    "    \"\"\"\n",
    "    Test that pure functions compose correctly\n",
    "    \"\"\"\n",
    "    # Test the full pipeline\n",
    "    result = build_sales_analysis_pipeline(test_df)\n",
    "    \n",
    "    # Check that all expected columns are present\n",
    "    expected_columns = {\"date\", \"customer\", \"product\", \"category\", \n",
    "                       \"amount\", \"total_with_tax\", \"purchase_size\", \"season\"}\n",
    "    actual_columns = set(result.columns)\n",
    "    \n",
    "    assert expected_columns.issubset(actual_columns), f\"Missing columns: {expected_columns - actual_columns}\"\n",
    "    print(\"✅ Test passed: Pipeline produces all expected columns\")\n",
    "    \n",
    "    # Test that data transformations work end-to-end\n",
    "    collected = result.collect()\n",
    "    assert len(collected) == 1, \"Expected 1 row in result\"\n",
    "    \n",
    "    row = collected[0]\n",
    "    assert row[\"season\"] == \"Summer\", f\"Expected Summer for June, got {row['season']}\"\n",
    "    assert row[\"purchase_size\"] == \"Medium\", f\"Expected Medium, got {row['purchase_size']}\"\n",
    "    \n",
    "    print(\"✅ Test passed: End-to-end pipeline transformations work correctly\")\n",
    "\n",
    "# Run the tests\n",
    "test_categorize_purchase_size()\n",
    "test_add_tax_column()\n",
    "test_pipeline_composition()\n",
    "\n",
    "print(\"\\n🎉 All tests passed! Pure functions are easily testable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Configuration and Parameters Functionally\n",
    "\n",
    "Let's demonstrate how to handle configuration and parameters in a functional way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Functional Configuration Patterns ===\")\n",
    "\n",
    "# ✅ GOOD: Configuration as parameters (dependency injection)\n",
    "class SalesConfig:\n",
    "    \"\"\"\n",
    "    Configuration class - immutable configuration object\n",
    "    \"\"\"\n",
    "    def __init__(self, tax_rate=0.08, high_value_threshold=100.0, \n",
    "                 date_format=\"yyyy-MM-dd\"):\n",
    "        self.tax_rate = tax_rate\n",
    "        self.high_value_threshold = high_value_threshold\n",
    "        self.date_format = date_format\n",
    "\n",
    "def create_configurable_pipeline(config):\n",
    "    \"\"\"\n",
    "    Higher-order function: returns a configured transformation pipeline\n",
    "    This is a functional approach to configuration\n",
    "    \"\"\"\n",
    "    def pipeline(df):\n",
    "        return (df\n",
    "                .withColumn(\"date\", F.to_date(F.col(\"date\"), config.date_format))\n",
    "                .withColumn(\"tax\", F.col(\"amount\") * F.lit(config.tax_rate))\n",
    "                .withColumn(\"total_with_tax\", F.col(\"amount\") + F.col(\"tax\"))\n",
    "                .filter(F.col(\"amount\") >= config.high_value_threshold)\n",
    "                .transform(categorize_purchase_size)\n",
    "                .transform(add_seasonal_info))\n",
    "    return pipeline\n",
    "\n",
    "# Usage with different configurations\n",
    "print(\"\\n1. Standard configuration:\")\n",
    "standard_config = SalesConfig()\n",
    "standard_pipeline = create_configurable_pipeline(standard_config)\n",
    "standard_result = standard_pipeline(sales_df)\n",
    "print(f\"Standard pipeline created with tax rate: {standard_config.tax_rate}\")\n",
    "print(f\"Records after filtering (threshold ${standard_config.high_value_threshold}): {standard_result.count()}\")\n",
    "\n",
    "print(\"\\n2. High-tax configuration:\")\n",
    "high_tax_config = SalesConfig(tax_rate=0.15, high_value_threshold=200.0)\n",
    "high_tax_pipeline = create_configurable_pipeline(high_tax_config)\n",
    "high_tax_result = high_tax_pipeline(sales_df)\n",
    "print(f\"High-tax pipeline created with tax rate: {high_tax_config.tax_rate}\")\n",
    "print(f\"Records after filtering (threshold ${high_tax_config.high_value_threshold}): {high_tax_result.count()}\")\n",
    "\n",
    "print(\"\\nBenefits of functional configuration:\")\n",
    "print(\"- No global state or side effects\")\n",
    "print(\"- Easy to test with different configurations\")\n",
    "print(\"- Immutable configuration objects\")\n",
    "print(\"- Dependency injection pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Anti-Patterns to Avoid\n",
    "\n",
    "Let's examine common anti-patterns that violate functional principles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Anti-Patterns to Avoid ===\")\n",
    "\n",
    "# ❌ ANTI-PATTERN 1: Global state modification\n",
    "print(\"\\n❌ ANTI-PATTERN 1: Global state modification\")\n",
    "\n",
    "# Global variable (bad!)\n",
    "processing_stats = {\"records_processed\": 0, \"errors\": 0}\n",
    "\n",
    "def bad_transform_with_global_state(df):\n",
    "    \"\"\"\n",
    "    BAD: This function modifies global state (side effect)\n",
    "    Makes the function impure and hard to test\n",
    "    \"\"\"\n",
    "    global processing_stats\n",
    "    \n",
    "    result = df.filter(F.col(\"amount\") > 100)\n",
    "    \n",
    "    # Side effect: modifying global state\n",
    "    processing_stats[\"records_processed\"] += result.count()  # Also an action!\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"This function modifies global state and calls actions - both bad practices!\")\n",
    "\n",
    "# ❌ ANTI-PATTERN 2: Actions inside transformation functions\n",
    "print(\"\\n❌ ANTI-PATTERN 2: Actions inside transformation functions\")\n",
    "\n",
    "def bad_transform_with_actions(df):\n",
    "    \"\"\"\n",
    "    BAD: Calling actions inside transformation logic\n",
    "    Breaks lazy evaluation and makes function impure\n",
    "    \"\"\"\n",
    "    filtered_df = df.filter(F.col(\"amount\") > 100)\n",
    "    \n",
    "    # Bad: action inside transformation function\n",
    "    count = filtered_df.count()\n",
    "    print(f\"Filtered {count} records\")  # Side effect\n",
    "    \n",
    "    # Bad: another action\n",
    "    if count > 0:\n",
    "        filtered_df.show(5)  # Side effect\n",
    "    \n",
    "    return filtered_df.withColumn(\"processed\", F.lit(True))\n",
    "\n",
    "print(\"This function calls count() and show() - breaking lazy evaluation!\")\n",
    "\n",
    "# ❌ ANTI-PATTERN 3: Exception handling that masks errors\n",
    "print(\"\\n❌ ANTI-PATTERN 3: Exception handling that masks errors\")\n",
    "\n",
    "def bad_transform_with_hidden_errors(df):\n",
    "    \"\"\"\n",
    "    BAD: Swallowing exceptions makes debugging difficult\n",
    "    Pure functions should be predictable\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return df.withColumn(\"invalid_column\", F.col(\"nonexistent_column\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")  # Side effect\n",
    "        return df  # Hiding the error!\n",
    "\n",
    "print(\"This function hides errors and has side effects!\")\n",
    "\n",
    "print(\"\\n✅ BETTER PATTERNS:\")\n",
    "print(\"- Keep transformations pure (no actions, no global state)\")\n",
    "print(\"- Handle configuration through parameters\")\n",
    "print(\"- Let errors propagate naturally for better debugging\")\n",
    "print(\"- Use actions only at pipeline boundaries\")\n",
    "print(\"- Return metrics/stats as part of the result, not side effects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Actions\n",
    "\n",
    "When you do need to use actions, here are some best practices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Best Practices for Using Actions ===\")\n",
    "\n",
    "# ✅ GOOD: Consolidate actions at pipeline boundaries\n",
    "def execute_sales_pipeline_with_monitoring(df, config):\n",
    "    \"\"\"\n",
    "    Good pattern: All side effects in one place\n",
    "    - Pure transformations separated from actions\n",
    "    - Monitoring and logging consolidated\n",
    "    - Clear separation of concerns\n",
    "    \"\"\"\n",
    "    print(\"=== Starting Sales Pipeline ===\")\n",
    "    \n",
    "    # Pure transformation pipeline\n",
    "    pipeline = create_configurable_pipeline(config)\n",
    "    transformed_df = pipeline(df)\n",
    "    \n",
    "    # Actions consolidated at the boundary\n",
    "    print(f\"\\nInput records: {df.count()}\")\n",
    "    print(f\"Output records: {transformed_df.count()}\")\n",
    "    print(f\"Filtering threshold: ${config.high_value_threshold}\")\n",
    "    print(f\"Tax rate applied: {config.tax_rate * 100}%\")\n",
    "    \n",
    "    print(\"\\n=== Sample Results ===\")\n",
    "    transformed_df.show()\n",
    "    \n",
    "    print(\"\\n=== Category Distribution ===\")\n",
    "    transformed_df.groupBy(\"purchase_size\").count().show()\n",
    "    \n",
    "    return transformed_df\n",
    "\n",
    "# ✅ GOOD: Actions for different purposes\n",
    "def demonstrate_appropriate_actions(df):\n",
    "    \"\"\"\n",
    "    Demonstrates appropriate use of different actions\n",
    "    \"\"\"\n",
    "    pipeline = create_configurable_pipeline(SalesConfig())\n",
    "    result_df = pipeline(df)\n",
    "    \n",
    "    print(\"=== Appropriate Actions ===\")\n",
    "    \n",
    "    # 1. count() for monitoring/logging\n",
    "    record_count = result_df.count()\n",
    "    print(f\"1. Monitoring: {record_count} records processed\")\n",
    "    \n",
    "    # 2. show() for development/debugging\n",
    "    print(\"\\n2. Development preview:\")\n",
    "    result_df.show(3)\n",
    "    \n",
    "    # 3. collect() for small datasets or aggregated results\n",
    "    print(\"\\n3. Collecting aggregated metrics (small result set):\")\n",
    "    metrics = result_df.agg(\n",
    "        F.avg(\"amount\").alias(\"avg_amount\"),\n",
    "        F.sum(\"total_with_tax\").alias(\"total_revenue\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    print(f\"   Average amount: ${metrics['avg_amount']:.2f}\")\n",
    "    print(f\"   Total revenue: ${metrics['total_revenue']:.2f}\")\n",
    "    \n",
    "    # 4. write() for persistence (simulated)\n",
    "    print(\"\\n4. Persistence action:\")\n",
    "    print(\"   result_df.write.mode('overwrite').parquet('/path/to/output')\")\n",
    "    print(\"   (Simulated - not actually writing)\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Execute examples\n",
    "config = SalesConfig(tax_rate=0.10, high_value_threshold=150.0)\n",
    "result1 = execute_sales_pipeline_with_monitoring(sales_df, config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "result2 = demonstrate_appropriate_actions(sales_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **Pure Functions**: \n",
    "   - Take DataFrames as input, return DataFrames as output\n",
    "   - No side effects (no actions, no global state modification)\n",
    "   - Deterministic and easily testable\n",
    "\n",
    "2. **Side Effects Management**:\n",
    "   - Confine side effects to pipeline boundaries\n",
    "   - Separate transformation logic from actions\n",
    "   - Use actions wisely and purposefully\n",
    "\n",
    "3. **Functional Composition**:\n",
    "   - Pure functions compose naturally\n",
    "   - Use `.transform()` for clean chaining\n",
    "   - Configuration through parameters, not global state\n",
    "\n",
    "4. **Testing Benefits**:\n",
    "   - Pure functions are easy to unit test\n",
    "   - No mocking required for core logic\n",
    "   - Predictable behavior\n",
    "\n",
    "**Next Steps**: In the next notebook, we'll explore PySpark's built-in functions and higher-order functions to maximize performance while maintaining functional purity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Create your own pure transformation functions:\n",
    "\n",
    "1. Write a pure function that adds a \"discount\" column based on purchase amount\n",
    "2. Write a pure function that categorizes customers by their purchase frequency\n",
    "3. Compose these functions with existing ones in a pipeline\n",
    "4. Write tests for your pure functions\n",
    "5. Create a boundary function that executes actions on your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your exercise code here\n",
    "\n",
    "def add_discount_column(df, discount_rate=0.05):\n",
    "    \"\"\"\n",
    "    Your pure function: Add discount calculation\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def categorize_customer_frequency(df):\n",
    "    \"\"\"\n",
    "    Your pure function: Categorize customers by purchase frequency\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def test_your_functions():\n",
    "    \"\"\"\n",
    "    Test your pure functions\n",
    "    \"\"\"\n",
    "    # Your tests here\n",
    "    pass\n",
    "\n",
    "def execute_your_pipeline(df):\n",
    "    \"\"\"\n",
    "    Boundary function with actions\n",
    "    \"\"\"\n",
    "    # Your pipeline execution here\n",
    "    pass\n",
    "\n",
    "# Run your exercise\n",
    "# test_your_functions()\n",
    "# execute_your_pipeline(sales_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}